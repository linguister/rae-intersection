from tqdm import tqdm
import json, random

# Para crear documentaci√≥n: pdoc --html src/utils.py --force

def save_dict(dic, file):
    """Guarda diccionario como json.
    
    Args
    ----------
    dic : dict
        Diccionario a guardar.
    file : str
        Archivo de salida.
    """
    with open(file, 'w') as fp:
        json.dump(dic, fp)

def load_dict(file):
    """Carga json como diccionario.
    
    Args
    ----------
    file : dict
        Archivo json.

    Returns
    -------
    dict
        Diccionario.
    """
    with open(file, 'r') as fp:
        return json.load(fp)
    
def load_dicts(files):
    """Carga y une m√∫ltiples archivos json en un diccionario.
    
    Args
    ----------
    files : list
        Lista de archivos json.

    Returns
    -------
    dict
        Diccionario.
    """
    res = {}
    for file in files:
        res.update(load_dict(file))
    return res

def df_to_dict(df):
    """Convierte DF en diccionario con listas.
    
    Args
    ----------
    df : pd.DataFrame
        DataFrame.

    Returns
    -------
    dict
        Diccionario donde las `keys` son los nombres columnas y los `values` son las columnas (como listas).
    """
    res = {}
    for c in df.columns:
        res[c] = df[c].tolist()
    return res

def words_with_word(drae, target_word):
    """Lista de todas las palabras que contienen `target_word` en su definici√≥n.

    Args
    ----------
    drae : dict
        Diccionario de la RAE.
    target_word : str
        Palabra que comprobar.

    Returns
    -------
    list
        Lista de tuplas: `(palabra, acepci√≥n)`
    """
    target_id = drae[target_word]['id']
    res = []
    for word in drae:
        for i in range(len(drae[word]['defs'])): # Para cada acepci√≥n
            rel_ids = drae[word]['rel_ids'][i]
            if target_id in '|'.join(rel_ids): # Si el 'target_id' est√° en la acepci√≥n, a√±adir palabra y acepci√≥n
                res.append((word, drae[word]['defs'][i]))
                break # Con que una acepci√≥n tenga la palabra, `word` ya queda registrada (adem√°s, con su acepci√≥n m√°s com√∫n)
    return res

def get_kinds(drae, word):
    """Tipos de la palabra seg√∫n sus definiciones.

    Args
    ----------
    drae : dict
        Diccionario de la RAE.
    word : str
        Palabra a buscar en su forma diccionario (ej. `fresa1`).

    Returns
    -------
    list
        Lista con los tipos de la palabra.
    """
    abrev = ABREV
    kinds = {}
    for kind in ABREV:
        for abr in abrev[kind]:
            kinds[abr] = kind
    res = []
    for d in drae[word]['defs']:
        start = d.split('. ')[1] + '.'
        if start in kinds and kinds[start] not in res: # Abreviatura est√° y no est√° registrado el tipo
            res.append(kinds[start])
    return res

def leave_single_kind(df):
    """Deja √∫nicamente palabras de 1 tipo (incluyendo polisemia y homonimia).

    Args
    ----------
    df : pd.DataFrame
        DataFrame de palabras.

    Returns
    -------
    pd.DataFrame
        DataFrame de palabras con s√≥lo 1 tipo.
    """
    # Reducir en homonimia
    aux = df.groupby('simple_word')['kinds'].nunique().reset_index()
    aux = aux[aux['kinds'] == 1] # Palabras con s√≥lo 1 tipo
    df = df[df['simple_word'].isin(aux['simple_word'])] # Dejar s√≥lo las que tengan 1 tipo
    # Reducir en polisemia (procesar despu√©s, porque si no palabras como `fresa` permanecen)
    df = df[~df['kinds'].str.contains(',')] # Eliminar las que tengan `,` en el tipo
    return df

def set_commonness(row):
    """Determina cu√°nto de com√∫n es una palabra en un rango del 0 (muy rara) al 4 (com√∫n).

    Args
    ----------
    row : pd.Series
        Fila de una palabra.

    Returns
    -------
    int
        Nivel de com√∫n.
    """
    if row['def_perc'] >= 95: # Palabras comod√≠n (aparecen en muchas definiciones)
        return 4
    if row['crea_perc'] >= 80 and row['ngram_perc'] >= 80: # Muy frecuente
        return 3
    if row['crea_perc'] >= 50 and row['ngram_perc'] >= 50: # Menos frecuente
        return 2
    if (row['crea_perc'] >= 30 and row['ngram_perc'] >= 30) or row['def_freq'] >= 5: # Menos frecuente a√∫n o no tan frecuente pero aparece en m√°s de 5 definiciones
        return 1
    return 0 # Casi no aparece como palabra

def exclude_group(drae, group):
    """Excluye acepciones que pertenecen a un grupo determinado de tecnicismos (p. ej. regionalismos).

    Args
    ----------
    drae : dict
        Diccionario de la RAE.
    group : list
        Grupo de abreviaturas que se quieren eliminar.

    Returns
    -------
    dict
        Diccionario con t√©rminos del grupo exclu√≠dos. Si una palabra pierde todas sus acepciones se quita del diccionario.
    """
    words_to_remove = []
    for word in tqdm(drae):
        i = 0 # √çndice de acepci√≥n a borrar
        j = 0 # √çndice total de acepciones, para saber cu√°ndo he llegado al final
        total_len = len(drae[word]['defs']) # Total de acepciones (en el momento inicial)
        while j < total_len:
            definition = drae[word]['defs'][i]
            deleted = False
            for term in group: # Para cada t√©rmino a excluir
                if term in definition: # Si el t√©rmino aparece en la acepci√≥n
                    del drae[word]['defs'][i]
                    del drae[word]['abrev'][i]
                    del drae[word]['rel_ids'][i]
                    deleted = True
                    break
            if not deleted:
                i += 1
            j += 1
        if len(drae[word]['defs']) == 0: # Si la palabra ha perdido todas las acepciones, eliminar palabra
            words_to_remove.append(word)
    for word in words_to_remove:
        del drae[word]
    return drae

def get_random_word(df, commonness=None, appear_lim=None):
    """Selecciona palabra aleatoria de rareza `commonness` y l√≠mite de acepciones `appear_lim`.

    Args
    ----------
    df : pd.DataFrame
        DataFrame de palabras.
    commonness : None or int
        N√∫mero del `1` al `4` (`0` y `5` suelen estar exclu√≠dos).
    appear_lim : None or int
        N√∫mero l√≠mite de acepciones en las que la palabra puede aparecer.

    Returns
    -------
    str
        Palabra aleatoria dentro de los par√°metros datos.
    """
    temp = df.copy()
    # print(commonness, appear_lim)
    if commonness is not None: # Si la rareza est√° definida
        temp = df[df['commonness'] == commonness].copy()
    if appear_lim: # Si el l√≠mite apariciones est√° definido
        temp = temp[temp['def_freq'] >= appear_lim]
    return temp.sample(1)['word'].iloc[0]

def get_acep_num(acep): 
    """N√∫mero de la acepci√≥n.

    Args
    ----------
    acep : str
        Acepci√≥n objetivo.

    Returns
    -------
    int
        N√∫mero (ordinal) de la acepci√≥n.
    """
    try:
        num = acep.split('.')[0]
        return int(num)
    except:
        raise Exception('La acepci√≥n no contiene n√∫mero')
        
def add_commonness(www, df):
    """A√±ade rareza a `www` (lista de soluciones).

    Args
    ----------
    www: list of tuple
        Lista de soluciones.
    df: pd.DataFrame
        DataFrame de palabras.

    Returns
    -------
    list of tuple
        Lista de tripletas `(palabra, acepci√≥n, rareza)`.
    """
    return [(word, acep, df[df['word'] == word]['commonness'].iloc[0]) for word, acep in www] # Asociar rareza a palabras encontradas

def limit_defs(www, limit_acep=None):
    """Limita el ordinal de las acepciones.

    Args
    ----------
    www: list of tuple
        Lista de soluciones.
    limit_acep: None or int
        L√≠mite del ordinal de las acepciones.

    Returns
    -------
    list of tuple
        `www` con restricciones aplicadas.
    """
    return [(word, acep) for word, acep in www if get_acep_num(acep) <= limit_acep] # Limita a acepciones con ordinal menor o igual que 'limit_acep'

def pick_solutions(solutions, target_word, hints, avoid_common=False):
    """Decide si en las soluciones est√°n las dificultades deseadas, en cuyo caso devuelve una muestra en orden para mostrar. La `target_word` no puede aparecer entre las soluciones.

    Args
    ----------
    solutions: list of tuple
        Lista de soluciones con rareza: [(palabra, definici√≥n, rareza)].
    target_word: str
        Palabra objetivo.
    hints: list
        Rareza de las pistas.
    avoid_common: bool
        Determina si eliminar candidatos que su deletreo inicial (primeras tres letras) coincida con la `target_word` (P. ej., 'pulm√≥n' y 'pulmonar').

    Returns
    -------
    bool or list of tuple
        Devuelve una muestra de soluciones con las rarezas solicitadas. En caso de no ser posible devuelve `False`.
    """
    count = {h: hints.count(h) for h in set(hints)}
    sol_count = {h: [] for h in set(hints)}
    random.shuffle(solutions)
    for sol in solutions:
        diff = sol[-1]
        if diff in sol_count and len(sol_count[diff]) < count[diff] and sol[0] != target_word and (avoid_common and sol[0][:3] != target_word[:3]): # Si dificultad adecuada y l√≠mite no alcanzado y palabra no misma que la buscada e inicio de palabra no coincide
            sol_count[diff].append(sol)
    for h in sol_count:
        if len(sol_count[h]) < count[h]: # Si no hay suficientes pistas
            return False
    res = []
    for hint in hints:
        res.append(sol_count[hint].pop(0)) # A√±ade soluci√≥n a la vez que la elimina del diccionario
    return res

def show_letter(word, index):
    """Muestra letra `index` de `word` (con texto de acompa√±amiento).

    Args
    ----------
    word : str
        Palabra a mostrar.
    index: int
        √çndice de la letra a mostrar.
    """
    description = f"Letra {'primera' if index == 0 else ('√∫ltima' if index == -1 else 'intermedia')}"
    prefix = '' if index == 0 else '_'
    suffix = '' if index == -1 else '_'
    print(f'{description}: {prefix}{word[index]}{suffix}')

def show_length(word):
    """Muestra longitud de `word` (con texto de acompa√±amiento).

    Args
    ----------
    word : str
        Palabra a mostrar.
    """
    infix = '*'*(len(word)-2)
    print(f'Aspecto: {word[0]}{infix}{word[-1]}')

def show_words(solutions, df, interval=(0,-1)):
    """Muestra el intervalo determinado de soluciones (con texto de acompa√±amiento).

    Args
    ----------
    solutions : list of tuple
        Lista de tripletas `(palabra, acepci√≥n, rareza)`.
    df: pd.DataFrame
        DataFrame de palabras.
    interval: tuple
        Pareja de √≠ndices de las soluciones a mostrar. Para cubrir todas ellas
    """
    start = interval[0]
    end = interval[-1] + (0 if interval[-1] > 0 else len(solutions)+1)
    for i, (word, definition, commonness) in enumerate(solutions):
        if start <= i and i < end:
            print(f"Palabra {i+1}: {df[df['word'] == word]['simple_word'].iloc[0]} ({'‚òÖ'*commonness if commonness > 0 else 'üíÄ'})")
            
def show_content(solutions, df):
    """Muestra las acepciones de las soluciones (con texto de acompa√±amiento).

    Args
    ----------
    solutions : list of tuple
        Lista de tripletas `(palabra, acepci√≥n, rareza)`.
    """
    for i, (word, definition, commonness) in enumerate(solutions):
        print(f"Palabra {i+1}: {df[df['word'] == word]['simple_word'].iloc[0]} ({'‚òÖ'*commonness if commonness > 0 else 'üíÄ'})")
        print(f" > {definition}\n")

def modify_def(target_word, definition, l=5):
    """Modifica la definici√≥n para ocultar target_word.

    Args
    ----------
    target_word : str
        Palabra objetivo.
    definition: str
        Definici√≥n a modificar.
    l: int
        Longitud de la comparaci√≥n.

    Returns
    -------
    str
        Definici√≥n modificada.
    """
    modified_def = ''
    l = min(l, len(target_word) - 1) # Longitud de la comparaci√≥n
    words_in_def = definition.replace(',', ' ,').replace('.', ' .').split(' ')
    for w in words_in_def:
        simplified_w = w.lower().replace('√°', 'a').replace('√©', 'e').replace('√≠', 'i').replace('√≥', 'o').replace('√∫', 'u') # Eliminar tildes
        if simplified_w[:l] == target_word.lower().replace('√°', 'a').replace('√©', 'e').replace('√≠', 'i').replace('√≥', 'o').replace('√∫', 'u')[:l]:
            modified_def += '‚ñ†' + ' '
        else:
            modified_def += w + ' '
    return modified_def.replace(' ,', ',').replace(' .', '.')
            
ABR_VERB = ['aux.', 'copulat.', 'impers.', 'intr.', 'prnl.', 'tr.', 'part.'] # Verbos
ABR_SUST = ['f.', 'm.', 'n.'] # Sustantivos
ABR_ADJ = ['adj.'] # Adjetivos
ABR_ADV = ['adv.'] # Adverbios
ABR_PREP = ['prep.', 'contracc.'] # Preposiciones
ABR_ART = ['art.'] # Art√≠culos
ABR_PRON = ['pron.'] # Pronombres
ABR_INTERJ = ['interj.'] # Interjeciones
ABR_CONJ = ['conj.'] # Conjunciones
ABR_ONOMAT = ['onomat.'] # Onomatopeyas
ABR_ELEM = ['elem.', 'pref.', 'suf.'] # Elementos compositivos
ABR_EXPR = ['expr.'] # Expresiones

ABREV = {'sust': ABR_SUST, 'verb': ABR_VERB, 'adj': ABR_ADJ, 'adv': ABR_ADV, 'prep': ABR_PREP, 'art': ABR_ART, 'pron': ABR_PRON, 'interj': ABR_INTERJ, 'conj': ABR_CONJ, 'onomat': ABR_ONOMAT, 'elem': ABR_ELEM, 'expr': ABR_EXPR}

ABECEDARIO = ['a1', 'be1', 'ce1', 'de1', 'e1', 'efe', 'ge1', 'hache', 'i', 'jota1', 'ka', 'ele1', 'eme1', 'ene', 'e√±e', 'o1', 'pe', 'cu1', 'erre1', 'ese1', 'te1', 'u1', 'uve', 'equis', 'y', 'zeta1']

STOPWORDS = []

# https://dle.rae.es/contenido/abreviaturas-y-signos-empleados
ABR_REG = {'√Ål.': '√Ålava', 'Alb.': 'Albacete', 'Alm.': 'Almer√≠a', 'Am.': 'Am√©rica', 'Am. Cen.': 'Am√©rica Central', 'Am. Mer.': 'Am√©rica Meridional', 'And.': 'Andaluc√≠a', 'Ant.': 'Antillas', 'Ar.': 'Arag√≥n', 'Arg.': 'Argentina', 'Ast.': 'Asturias', '√Åv.': '√Åvila', 'Bad.': 'Badajoz', 'Bal.': 'Islas Baleares', 'Bil.': 'Bilbao', 'Bol.': 'Bolivia', 'Burg.': 'Burgos', 'C√°c.': 'C√°ceres', 'C√°d.': 'C√°diz', 'Can.': 'Canarias', 'Cantb.': 'Cantabria', 'Cast.': 'Castilla', 'Cat.': 'Catalu√±a', 'Col.': 'Colombia', 'C√≥rd.': 'C√≥rdoba', 'C. Real': 'Ciudad Real', 'C. Rica': 'Costa Rica', 'Cuen.': 'Cuenca', 'Ec.': 'Ecuador', 'EE. UU.': 'Estados Unidos', 'El Salv.': 'El Salvador', 'Esp.': 'Espa√±a', 'Ext.': 'Extremadura', 'Filip.': 'Filipinas', 'Gal.': 'Galicia', 'Gran.': 'Granada', 'Gran Can.': 'Gran Canaria', 'Guad.': 'Guadalajara', 'Guat.': 'Guatemala', 'Guin.': 'Guinea Ecuatorial', 'Guip.': 'Guip√∫zcoa', 'Hond.': 'Honduras', 'Huel.': 'Huelva', 'Hues.': 'Huesca', 'Mad.': 'Madrid', 'M√°l.': 'M√°laga', 'Man.': 'La Mancha', 'M√©x.': 'M√©xico', 'Mur.': 'Murcia', 'Nav.': 'Navarra', 'Nic.': 'Nicaragua', 'Pal.': 'Palencia', 'Pan.': 'Panam√°', 'Par.': 'Paraguay', 'P. Rico': 'Puerto Rico', 'P. Vasco': 'Pa√≠s Vasco', 'R. Dom.': 'Rep√∫blica Dominicana', 'Sal.': 'Salamanca', 'Seg.': 'Segovia', 'Sev.': 'Sevilla', 'Sor.': 'Soria', 'Ter.': 'Teruel', 'Tol.': 'Toledo', 'Ur.': 'Uruguay', 'Val.': 'Valencia', 'Vall.': 'Valladolid', 'Ven.': 'Venezuela', 'Vizc.': 'Vizcaya', 'Zam.': 'Zamora', 'Zar.': 'Zaragoza'}
ABR_REG.update({'Chile': 'Chile', 'Cuba': 'Cuba', 'Per√∫': 'Per√∫'})

ABR_TEMA = {'Ac√∫s.': 'ac√∫stica', 'Aer.': 'aeron√°utica', 'Agr.': 'agricultura', 'Alq.': 'alquimia', 'Anat.': 'anatom√≠a', 'Antrop.': 'antropolog√≠a', 'Arq.': 'arquitectura', 'Arqueol.': 'arqueolog√≠a', 'Astron.': 'astronom√≠a', 'Astrol.': 'astrolog√≠a', 'Biol.': 'biolog√≠a', 'Bioqu√≠m.': 'bioqu√≠mica', 'Bot.': 'bot√°nica', 'Carp.': 'carpinter√≠a', 'Cineg.': 'cineg√©tica', 'Cinem.': 'cinematograf√≠a', 'Com.': 'comercio', 'Constr.': 'construcci√≥n', 'Dep.': 'deportes', 'Der.': 'derecho', 'Ecd.': 'ecd√≥tica', 'Ecol.': 'ecolog√≠a', 'Econ.': 'econom√≠a', 'Electr.': 'electricidad; electr√≥nica', 'Equit.': 'equitaci√≥n', 'Esc.': 'escultura', 'Esgr.': 'esgrima', 'Estad.': 'estad√≠stica', 'Fil.': 'filosof√≠a', 'F√≠s.': 'f√≠sica', 'Fisiol.': 'fisiolog√≠a', 'Fon.': 'fon√©tica; fonolog√≠a', 'F√≥rm.': 'f√≥rmula', 'Fotogr.': 'fotograf√≠a', 'Geogr.': 'geograf√≠a', 'Geol.': 'geolog√≠a', 'Geom.': 'geometr√≠a', 'Gram.': 'gram√°tica', 'Her√°ld.': 'her√°ldica', 'Impr.': 'imprenta', 'Inform.': 'inform√°tica', 'Ingen.': 'ingenier√≠a', 'Ling.': 'ling√º√≠stica', 'Mar.': 'marina', 'Mat.': 'matem√°ticas', 'Mec.': 'mec√°nica', 'Med.': 'medicina', 'Meteor.': 'meteorolog√≠a', 'M√©tr.': 'm√©trica', 'Mil.': 'milicia', 'Mit.': 'mitolog√≠a', 'M√∫s.': 'm√∫sica', 'Numism.': 'numism√°tica', '√ìpt.': '√≥ptica', 'Ortogr.': 'ortograf√≠a', 'Parapsicol.': 'parapsicolog√≠a', 'Pint.': 'pintura', 'Psicol.': 'psicolog√≠a', 'Psiquiatr.': 'psiquiatr√≠a', 'Qu√≠m.': 'qu√≠mica', 'Rel.': 'religi√≥n', 'Ret.': 'ret√≥rica', 'S√≠mb.': 's√≠mbolo', 'Sociol.': 'sociolog√≠a', 'Taurom.': 'tauromaquia', 'Tecnol.': 'tecnolog√≠as', 'Telec.': 'telecomunicaci√≥n', 'T. lit.': 'teor√≠a literaria', 'Topogr.': 'topograf√≠a', 'Transp.': 'transportes', 'TV.': 'televisi√≥n', 'Urb.': 'urbanismo', 'Veter.': 'veterinaria', 'Zool.': 'zoolog√≠a'}

ABR_DESUS = {'ant.': 'anticuado; antiguo', 'desus.': 'desusado', 'p. us.': 'poco usado'}

ABREVIATURAS = {'a.': 'alto', 'abl.': 'ablativo', 'abrev.': 'abreviaci√≥n', 'acep.': 'acepci√≥n', 'acort.': 'acortamiento', 'acr√≥n.': 'acr√≥nimo', 'act.': 'activo', 'acus.': 'acusativo', 'adapt.': 'adaptaci√≥n; adaptado', 'adj.': 'adjetivo', 'adv.': 'adverbio; adverbial', 'advers.': 'adversativo', 'afect.': 'afectivo', 'af√©r.': 'af√©resis', 'aim.': 'aimara', 'al.': 'alem√°n', 'alterac.': 'alteraci√≥n', 'alus.': 'alusi√≥n', 'amer.': 'americano', 'antonom.': 'antonomasia', 'apl.': 'aplicado', 'ap√≥c.': 'ap√≥cope', 'apos.': 'aposici√≥n', '√°r.': '√°rabe', 'arag.': 'aragon√©s', 'art.': 'art√≠culo', 'ast.': 'asturiano', 'at√≥m.': 'at√≥mico', 'aum.': 'aumentativo', 'aux.': 'auxiliar; verbo auxiliar', 'b.': 'bajo', 'berb.': 'bereber', 'c.': 'como', 'cat.': 'catal√°n', 'celtolat.': 'celtolatino', 'cf.': 'confer', 'cient.': 'cient√≠fico', 'cl√°s.': 'cl√°sico', 'coloq.': 'coloquial', 'comp.': 'comparativo', 'compos.': 'compositivo', 'conc.': 'concesivo', 'condic.': 'condicional', 'conj.': 'conjunci√≥n', 'conjug.': 'conjugaci√≥n', 'conjunt.': 'conjuntivo', 'contracc.': 'contracci√≥n', 'copulat.': 'copulativo; verbo copulativo', 'cult.': 'culto', 'dat.': 'dativo', 'deformac.': 'deformaci√≥n', 'dem.': 'demostrativo', 'der.': 'derivado', 'desc.': 'desconocido', 'despect.': 'despectivo', 'deter.': 'determinado', 'dialect.': 'dialectal', 'dim.': 'diminutivo', 'disc.': 'discutido', 'distrib.': 'distributivo', 'disyunt.': 'disyuntivo', 'elem.': 'elemento', 'escr.': 'escrito', 'esp.': 'espa√±ol', 'estud.': 'estudiantil', 'etim.': 'etimolog√≠a', 'eufem.': 'eufemismo; eufem√≠stico', 'excl.': 'exclamativo', 'expr.': 'expresi√≥n; expresivo', 'ext.': 'extensi√≥n', 'f.': 'femenino; nombre femenino', 'fest.': 'festivo', 'fig.': 'figurado', 'fr.': 'franc√©s', 'fr.': 'frase', 'frec.': 'frecuentativo', 'frec.': 'frecuentemente', 'fut.': 'futuro', 'gall.': 'gallego', 'gallegoport.': 'gallegoportugu√©s', 'galolat.': 'galolatino', 'genit.': 'genitivo', 'ger.': 'gerundio', 'germ.': 'german√≠a', 'germ.': 'germ√°nico', 'g√≥t.': 'g√≥tico', 'gr.': 'griego', 'guar.': 'guaran√≠', 'hebr.': 'hebreo', 'hisp.': 'hisp√°nico', 'ilat.': 'ilativo', 'imit.': 'imitaci√≥n; imitativo', 'imper.': 'imperativo', 'imperf.': 'imperfecto', 'impers.': 'impersonal; verbo impersonal', 'inc.': 'incierto', 'incoat.': 'incoativo', 'indef.': 'indefinido', 'indet.': 'indeterminado', 'indic.': 'indicativo', 'infant.': 'infantil', 'infinit.': 'infinitivo', 'infl.': 'influencia; influido; influjo', 'ingl.': 'ingl√©s', 'intens.': 'intensivo', 'interj.': 'interjecci√≥n; interjectivo', 'interrog.': 'interrogativo', 'intr.': 'intransitivo; verbo intransitivo', 'inus.': 'inusual', 'irl.': 'irland√©s', 'ir√≥n.': 'ir√≥nico', 'irreg.': 'irregular', 'it.': 'italiano', 'jap.': 'japon√©s', 'jerg.': 'jerga; jergal', 'lat.': 'lat√≠n; latino', 'leng.': 'lenguaje', 'leon.': 'leon√©s', 'loc.': 'locuci√≥n', 'm.': 'masculino; nombre masculino', '[u.] m.': '[usado] m√°s', 'm. or.': 'mismo origen', 'malson.': 'malsonante', 'may.': 'may√∫scula', 'metapl.': 'metaplasmo', 'met√°t.': 'met√°tesis', 'mod.': 'moderno', 'moz√°r.': 'moz√°rabe', 'n.': 'neutro', 'n. p.': 'nombre propio', 'neerl.': 'neerland√©s', 'neg.': 'negaci√≥n', 'negat.': 'negativo', 'n√≥rd.': 'n√≥rdico', 'n√∫m.': 'n√∫mero', 'occid.': 'occidental', 'occit.': 'occitano', 'onomat.': 'onomatopeya; onomatop√©yico', 'or.': 'origen', 'orient.': 'oriental', 'part.': 'participio', 'pas.': 'pasivo', 'perf.': 'perfecto', 'pers.': 'persona', 'person.': 'personal', 'peyor.': 'peyorativo', 'pl.': 'plural', 'po√©t.': 'po√©tico', 'ponder.': 'ponderativo', 'pop.': 'popular', 'port.': 'portugu√©s', 'poses.': 'posesivo', 'pref.': 'prefijo', 'prep.': 'preposici√≥n', 'prepos.': 'preposicional', 'pres.': 'presente', 'pret.': 'pret√©rito', 'prnl.': 'pronominal; verbo pronominal', 'pron.': 'pronombre', 'pronom.': 'pronominal', 'prov.': 'provenzal', 'ref.': 'referido', 'refl.': 'reflexivo', 'reg.': 'regular', '[marca] reg.': '[marca] registrada', 'regres.': 'regresivo', 'relat.': 'relativo', 'rur.': 'rural', 's.': 'sustantivo', 's√°nscr.': 's√°nscrito', 'sent.': 'sentido', 's√≠nc.': 's√≠ncopa', 'sing.': 'singular', 'subj.': 'subjuntivo', 'suf.': 'sufijo', 'sup.': 'superlativo', 'sust.': 'sustantivo', 't.': 'terminaci√≥n', '[conj.] t.': '[conjunci√≥n] temporal', '[u.] t.': '[usado] tambi√©n', 'Tb.': 'tambi√©n', 'tr.': 'transitivo; verbo transitivo', 'trad.': 'traducci√≥n', 'u.': 'usado', 'V.': 'v√©ase', 'var.': 'variante', 'verb.': 'verbal', 'vocat.': 'vocativo', 'vulg.': 'vulgar'}
